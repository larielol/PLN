{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyWvsqmojVf5"
      },
      "source": [
        "**Identificação do aluno**\n",
        "\n",
        "**Email:**\n",
        "\n",
        "**Matrícula:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehQP7aS5iHdD"
      },
      "source": [
        "# **Análise de Sentimentos em Reviews do IMDb**\n",
        "\n",
        "O principal objetivo desta tarefa é aplicar três modelos de aprendizado de máquina distintos - Regressão Logística, Naive Bayes e KNN - para realizar a análise de sentimento em um conjunto de dados de *reviews* de usuários sobre filmes no IMDb. Neste laboratório vamos aprender analisar diferentes valores dos parâmetros dos modelos, selecionando aqueles que tiveram melhor desempenho na validação cruzada. Além disso, vamos calcular as principais métricas utilizadas nesse tipo de tarefa e analisar o desempenho dos nossos modelos. Ao final desta tarefa, você deverá ter uma compreensão mais profunda de como esses modelos funcionam, suas vantagens e limitações quando aplicados a dados textuais do mundo real. Este conjunto de dados inclui avaliações de texto juntamente com rótulos de sentimento correspondentes (positivo ou negativo) para a aprendizagem supervisionada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbKHnZiNj2Uk"
      },
      "source": [
        "## **Bibliotecas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE7KzlmGj5eu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c966d6c8-5a94-49c0-901e-118c1cdb1654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "# Para a leitura e armazenamento estruturado dos dados\n",
        "import pandas as pd\n",
        "\n",
        "# Manipulação de texto\n",
        "import nltk\n",
        "from nltk                             import SnowballStemmer\n",
        "from nltk.tokenize                    import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Prepraração dos dados\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text  import CountVectorizer\n",
        "from sklearn.model_selection          import train_test_split\n",
        "from sklearn.preprocessing            import StandardScaler\n",
        "\n",
        "# Modelos de classificação\n",
        "from sklearn.linear_model import SGDClassifier            #Stocastic Gradient Descent\n",
        "from sklearn.naive_bayes import MultinomialNB             #Multinominal Naive Bayes\n",
        "from sklearn.neighbors import KNeighborsClassifier        #K-nearest Neihgbors\n",
        "\n",
        "# Avaliação\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjPuNmPvkFrq"
      },
      "source": [
        "## **Leitura dos dados**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste Lab, utilizamos um conjunto de dados com avaliações de filmes do IMDb, onde cada review é rotulado como positivo ou negativo. O objetivo é realizar uma análise de sentimentos, iniciando com a leitura dos dados que serão usados para treinar e avaliar modelos de classificação.\n"
      ],
      "metadata": {
        "id": "k280wy4bGrtc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIHxXL4CkE5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "3bcf39b6-075f-46df-cec9-d6bda4a6382a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 content sentiment\n",
              "3470   this movie joshua is extremely disturbing and ...       neg\n",
              "23859  this dvd appears to be targetted at someone wh...       neg\n",
              "17858  william hurt scuba diving scientist us agents ...       neg\n",
              "9965   this long winded film turns out to be less abo...       neg\n",
              "20220  not only was he invariably annoying to listen ...       neg\n",
              "5455   the lives of the saints starts off with an atm...       neg\n",
              "5656   there are many different versions of this one ...       neg\n",
              "11157  every once in a long while a movie will come a...       neg"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14d0df8f-e831-4aad-bc97-8dd12117ff99\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3470</th>\n",
              "      <td>this movie joshua is extremely disturbing and ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23859</th>\n",
              "      <td>this dvd appears to be targetted at someone wh...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17858</th>\n",
              "      <td>william hurt scuba diving scientist us agents ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9965</th>\n",
              "      <td>this long winded film turns out to be less abo...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20220</th>\n",
              "      <td>not only was he invariably annoying to listen ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5455</th>\n",
              "      <td>the lives of the saints starts off with an atm...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5656</th>\n",
              "      <td>there are many different versions of this one ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11157</th>\n",
              "      <td>every once in a long while a movie will come a...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14d0df8f-e831-4aad-bc97-8dd12117ff99')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-14d0df8f-e831-4aad-bc97-8dd12117ff99 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-14d0df8f-e831-4aad-bc97-8dd12117ff99');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6084c2be-57ee-4bc4-ab4e-28a8945aaa52\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6084c2be-57ee-4bc4-ab4e-28a8945aaa52')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6084c2be-57ee-4bc4-ab4e-28a8945aaa52 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5000,\n  \"fields\": [\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4990,\n        \"samples\": [\n          \"how can someone not like this movie this movie is so good that the first week i saw it on the shelf at the video store it was stolenbest horror movie everi mean he took the carrot and hewell you know hahahahow is that not funny the only movie that comes close to touching this is bride of chucky and that was just great\",\n          \"orca is not exactly bad but its not really richard harriss finest hour either as a demented ahablike fisherman harris gets into a game of death with a vengeful killer whale after killing the whales wife and unborn child charlotte rampling plays a whale expert who gets involved with harris she yells at him a lot about how important it is to leave nature alone he doesnt listen and somehow ends up in the arctic battling the revenge crazed whale there are no special effects to speak of except for what looks like a round mirror for a whales eye there are endless shots of harris reflected in the eye so the audience understands that the whale knows who he is bo derek as one of harriss crew has a particularly unpleasant run in with the orca and most of the supporting cast including robert carridine will sampson and keenan wynn dont fare very well either\",\n          \"frustrating to watch because of one mans stubbornness to leave his native country for the dream land in switzerland and what he does to achieve that creates heartache for all those involved along the journey he encounters scumbags who take advantage of other human suffering and desperation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"pos\",\n          \"neg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "df = pd.read_csv('https://gist.githubusercontent.com/issilva5/44c9406a85b0fed0d62668752cc31b09/raw/49e01d2e8011bdd83d0bc835a518e398ae319303/movie_reviews.csv')\n",
        "df = df.groupby('sentiment', group_keys=False).sample(n=2500, random_state=42)\n",
        "df.head(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH-X2HjGkxu9"
      },
      "source": [
        "Os dados estão distribuídos em duas classes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3dc3YC2kp2u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "c741edae-a032-4889-9380-078c475a9a98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           content\n",
              "sentiment         \n",
              "neg           2500\n",
              "pos           2500"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4992dffe-1f4d-499b-b410-006be65ca6e2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>neg</th>\n",
              "      <td>2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pos</th>\n",
              "      <td>2500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4992dffe-1f4d-499b-b410-006be65ca6e2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4992dffe-1f4d-499b-b410-006be65ca6e2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4992dffe-1f4d-499b-b410-006be65ca6e2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-35b2506c-6149-4a14-a231-70cd40c54f48\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35b2506c-6149-4a14-a231-70cd40c54f48')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-35b2506c-6149-4a14-a231-70cd40c54f48 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"pos\",\n          \"neg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2500,\n        \"max\": 2500,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2500\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df.groupby('sentiment').count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKlAipOJyvKD"
      },
      "source": [
        "A seguir criaremos uma lista com o texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKdtjVJXyj93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08e9b601-e95c-4a67-b74e-28a0216f7d70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this movie joshua is extremely disturbing and downright pointless it actually makes me shudder to think there are people who would enjoy watching it without giving away the story it is about a young boys reaction to his newborn sister and that is just the tip of the iceberg during the entirety of this movie the viewer is subjected to some of the most unsettling child behavior imaginable adding insult to injury by the end of this movie there is absolutely no real outcome except the fruition of pure evil at the hands of a child no less who outsmarted a whole group of dumb adults there is no redemption no justice served and a whole group of adults who are not smart enough to see what is going on around them frankly i did not enjoy watching this movie it was extremely unsettling even for those who might enjoy horror movies this movie could be too much despite the fact this movie was well acted the story itself is so disturbing that watching it was equivalent to a minute wait in a dentists waiting room in anticipation of some painful dental procedure\n"
          ]
        }
      ],
      "source": [
        "corpus = df['content'].tolist()\n",
        "print(corpus[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4Qyfdx0k64m"
      },
      "source": [
        "## **Limpeza dos dados**\n",
        "\n",
        "Antes de aplicar modelos de aprendizado de máquina, você precisará limpar e pré-processar os dados textuais. É esperado que você aplique pelo menos as seguintes tarefas de limpeza dos dados:\n",
        "\n",
        "- Tokenização\n",
        "- Remoção de palavras muito pequenas (<= 2) ou muito grandes (>= 15).\n",
        "- Remoção de stopwords.\n",
        "- Stemming."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3d4NDWGl0gp"
      },
      "outputs": [],
      "source": [
        "def remove_palavras_pequenas_grandes(tokens):\n",
        "  # Implemente uma função que recebe uma lista de tokens\n",
        "  # e retorna uma lista sem os tokens muito pequenos (< 2)\n",
        "  # ou muito grandes (> 15).\n",
        "  pass\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "  # Implemente uma função que recebe uma lista de tokens\n",
        "  # e retorna uma lista sem stopwords.\n",
        "  # Dica: use uma lista ou conjunto de stopwords e filtre os tokens com list comprehension.\n",
        "  pass\n",
        "\n",
        "def stemming(tokens, stemmer):\n",
        "  # Implemente uma função que recebe uma lista de tokens\n",
        "  # e retorna uma lista com os tokens stemmizados.\n",
        "  # Dica: use um stemmer como o PorterStemmer da biblioteca NLTK.\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNlpPU3EyiTn"
      },
      "outputs": [],
      "source": [
        "def process_corpus(corpus):\n",
        "  param_stemmer = SnowballStemmer('english')\n",
        "  corpus_processed = []\n",
        "  for document in corpus:\n",
        "    tokens = word_tokenize(document)\n",
        "    tokens = remove_palavras_pequenas_grandes(tokens)\n",
        "    tokens = remove_stopwords(tokens)\n",
        "    tokens = stemming(tokens, param_stemmer)\n",
        "    corpus_processed.append(\" \".join(tokens))\n",
        "  return corpus_processed\n",
        "\n",
        "corpus_processed = process_corpus(corpus)\n",
        "print(corpus_processed[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3FWA1Fz3kIB"
      },
      "source": [
        "## **Preparando os dados para os modelos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkykJyP33oL4"
      },
      "source": [
        "1. **Vetorização dos dados**\n",
        "\n",
        "Primeiramente, realize a vetorização dos dados. Lembre que o classificador naive bayes trabalha melhor com uma vetorização bag-of-words. Regressão logística e KNN podem trabalhar com outros tipos de vetorização ou podem necessitar de alguma normalização ou padronização. Porém, neste laboratório vamos utilizar a vetorização bag-of-words e padronizar os dados utilizando a z-score. Siga os passos abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pmHTGer3yPm"
      },
      "outputs": [],
      "source": [
        "# Você deve instanciar um vetorizador e aplicá-lo ao corpus processado. O naive bayes pressupõe frequências inteiras. Por esse motivo, devemos usar\n",
        "# um vetorizador binário. Dica: Use a classe CountVectorizer() para uma vetorização binária com contagens e armazene a vetorização na variável X.\n",
        "\n",
        "\n",
        "#Visualizando parte dos dados binarizados\n",
        "print(X.toarray()[0][:10])\n",
        "print(y[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaExf3qq4YqO"
      },
      "source": [
        "2. **Separação dos dados em conjunto de treinamento e teste**\n",
        "\n",
        "Agora, realize a partição treino e teste dos dados considerando o vetor bag-of-words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alzmjVAy4dIr"
      },
      "outputs": [],
      "source": [
        "# Você deve realizar a partição treino e teste dos dados aqui. Dica: Use train_test_split() passando os vetores X, y da célula anterior e escolhendo a porcentagem de separação.\n",
        "# Utilize 70% dos dados para treinamento. Isso pode ser feito através do parâmetro train_size\n",
        "# Utilize também os parâmetros random_state=42 e stratify=y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando se estamos mantendo o balanceamento no conjunto de treino e teste\n",
        "classes, counts = np.unique(y_train, return_counts=True)\n",
        "\n",
        "print('Dados de treino')\n",
        "for label, count in zip(classes, counts):\n",
        "    print(f\"{label}: {count}\")"
      ],
      "metadata": {
        "id": "RpS2s12bmRnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando se estamos mantendo o balanceamento no conjunto de treino e teste\n",
        "classes, counts = np.unique(y_test, return_counts=True)\n",
        "\n",
        "print('Dados de teste')\n",
        "for label, count in zip(classes, counts):\n",
        "    print(f\"{label}: {count}\")"
      ],
      "metadata": {
        "id": "722ExDAtlxA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Como já temos definidos quais são nossos dados de treinamento e teste, podemos criar as versões padronizadas desses dados para os algoritmos de\n",
        "# regressão logísticia e KNN. Para realizar a padronização, você pode utilizar a classe StandardScaler() e o método fit_transform() passando seus vetores\n",
        "# Faça a padronização para X_train e X_test armazenando cada resultado em uma nova variável (X_train_pad e X_test_pad)\n",
        "\n",
        "\n",
        "print(X_train_pad[0][:10])\n",
        "print(X_test_pad[0][:10])\n"
      ],
      "metadata": {
        "id": "Mq-HU0vx_PgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2ZCCuyr5X_X"
      },
      "source": [
        "## **Treinando modelos**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Selecionando Parâmetros**\n",
        "\n",
        "\n",
        "Nossos modelos possuem parâmetros. O naivebayes possui um parâmetro alpha que é relacionado a suavização de laplace; o KNN possui o K que indica quantos vizinhos devemos considerar como sendo os mais próximos; e a regressão logística apresenta o learning rate que diz se devemos ter passos mais apressados ou não para reduzir ou aumentar os valores dos pesos da função. Nesta estapa, vamos utilizar a validação cruzada para encontrar esses parâmetros"
      ],
      "metadata": {
        "id": "UrOIsxtZ4BWd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dmp5T7O6eFO"
      },
      "source": [
        "1. **Parâmetro alpha do Naive Bayes:**\n",
        "\n",
        "Vamos tentar encontrar o melhor parâmetro de suavização considerando `[0.5, 1, 1.5, 2, 2.5]`. Para isso, adapte a validação cruzada do código abaixo para iterar sobre esses valores e armazenar a métrica de f-score."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.model_selection as cv\n",
        "\n",
        "#n_splits indica a quantidade de splits que faremos\n",
        "cv = cv.StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "alphas = [0.5, 1, 1.5, 2, 2.5]\n",
        "\n",
        "for alpha in alphas:\n",
        "\n",
        "    metricas = []  # armazenar as métricas de cada fold\n",
        "\n",
        "    # Itera sobre cada fold\n",
        "    for train_idx, test_idx in cv.split(X_train, y_train):\n",
        "\n",
        "        # Separa os ids de treino e os de teste\n",
        "        X_train_cv, X_test_cv = X[train_idx], X[test_idx]\n",
        "        y_train_cv, y_test_cv = y[train_idx], y[test_idx]\n",
        "\n",
        "        # Nesse ponto instancie o modelo naive bayes para a variável modelo.\n",
        "        # Ele pode ser instanciando chamando a classe MultinomialNB() e passando o parâmetro alpha=seu_valor alfa atual\n",
        "\n",
        "        # Para treinar o modelo, utilize a variável model criada acima e chame o método .fit() passando os valores X e y de treino do fold atual\n",
        "\n",
        "        # Agora, vamos realizar as predições com nosso modelo e armazená-la na variável y_pred.\n",
        "        # Para isso, use a variável model e chame o método .predict() passando para ela os dados X de teste do fold\n",
        "\n",
        "        # Calculando a métrica e armazenando-a\n",
        "        metrica_atual = f1_score(y_test_cv, y_pred, average='micro', labels=['pos',' neg'])\n",
        "        metricas.append(metrica_atual)\n",
        "\n",
        "    print(f\"Alpha = {alpha:.1f} → Valor médio da métrica: {np.mean(metricas):.4f}\")"
      ],
      "metadata": {
        "id": "Kh6yRkIBD9RP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Parâmetro learning_rate da Regressão Logística**\n",
        "\n",
        "Vamos tentar encontrar o melhor parâmetro de learning rate para a regressão logística considerando os valores `[0.0001, 0.001, 0.01, 0.1]`. Para isso, adapte a validação cruzada do código abaixo para iterar sobre esses valores e armazenar a métrica de f-score."
      ],
      "metadata": {
        "id": "NSLN6AiBJoMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.model_selection as cv\n",
        "\n",
        "#n_splits indica a quantidade de splits que faremos\n",
        "cv = cv.StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
        "\n",
        "for lr in learning_rates:\n",
        "\n",
        "    metricas = []  # armazenar métricas de cada fold\n",
        "\n",
        "    # Itera sobre cada fold mas agora estamos usando os vetores\n",
        "    for train_idx, test_idx in cv.split(X_train_pad, y_train):\n",
        "\n",
        "        # Separa os ids de treino e os de teste\n",
        "        X_train_cv, X_test_cv = X[train_idx], X[test_idx]\n",
        "        y_train_cv, y_test_cv = y[train_idx], y[test_idx]\n",
        "\n",
        "        # Nesse ponto instancie o modelo de regressão logística para a variável modelo.\n",
        "        # Ele pode ser instanciando chamando a classe SGDClassifier() e passando o parâmetro eta0=seu_valor lr atual.\n",
        "        # Use os parâmetros learning_rate = 'constant' e também o random_state=42 para evitar aleatoriedade na inicialização dos pesos da função\n",
        "\n",
        "\n",
        "        # Treine o modelo e faça as predições nos mesmos moldes da validação cruzada da etapa do Naive Bayes\n",
        "\n",
        "        #Calculando a métrica e armazenando-a\n",
        "        metrica_atual = f1_score(y_test_cv, y_pred, average='micro', labels = ['pos', 'neg'])\n",
        "        metricas.append(metrica_atual)\n",
        "\n",
        "    print(f\"Learning Rate = {lr:.4f} → Valor médio da métrica: {np.mean(metricas):.4f}\")"
      ],
      "metadata": {
        "id": "BLJebVKFJuvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Parâmetro K-vizinhos do KNN**\n",
        "\n",
        " Vamos tentar encontrar o melhor parâmetro vizinhança para o KNN. para isso considere `K=[2, 3, 4, 5, 6, 7]`. Adapte a validação cruzada do código abaixo para iterar sobre esses valores e armazenar a métrica de f-score."
      ],
      "metadata": {
        "id": "Yk92QxYNNX08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.model_selection as cv\n",
        "\n",
        "#n_splits indica a quantidade de splits que faremos\n",
        "cv = cv.StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "K=[2, 3, 4, 5, 6, 7]\n",
        "\n",
        "for k in K:\n",
        "    metricas = []  # armazenar acurácias de cada fold\n",
        "\n",
        "    #Itera sobre cada fold mas agora estamos usando os vetores\n",
        "    for train_idx, test_idx in cv.split(X_train_pad, y_train):\n",
        "\n",
        "        #Separa os ids de treino e os de teste\n",
        "        X_train_cv, X_test_cv = X[train_idx], X[test_idx]\n",
        "        y_train_cv, y_test_cv = y[train_idx], y[test_idx]\n",
        "\n",
        "        #Nesse ponto instancie o modelo NKN e salve na variavel model.\n",
        "        #Ele pode ser instanciando chamando a classe KNeighborsClassifier() e passando o parâmetro n_neighbors= seu valor k atual.\n",
        "\n",
        "        # Treine o modelo e faça as predições nos mesmos moldes da validação cruzada da etapa do Naive Bayes\n",
        "\n",
        "        #Calculando a métrica e armazenando-a\n",
        "        metrica_atual = f1_score(y_test_cv, y_pred, average='micro', labels=['pos', 'neg'])\n",
        "        metricas.append(metrica_atual)\n",
        "\n",
        "    print(f\"K = {k} → Valor médio da métrica: {np.mean(metricas):.4f}\")"
      ],
      "metadata": {
        "id": "sH5Ab5DUN2Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Perguntas**\n",
        "\n",
        "Responda justificando"
      ],
      "metadata": {
        "id": "cfKF_CEwhQEl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Qual modelo demonstra superioridade no treinamento? Qual a sua intuição sobre essa superioridade?\n",
        "- Resposta:"
      ],
      "metadata": {
        "id": "wXRrd4P0hUaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Ao aplicarmos a suavização de laplace no modelo de Naive Bayes, os resultados pioram quando aumentamos o alfa? Por que isso acontece?\n",
        "- Resposta:"
      ],
      "metadata": {
        "id": "5ez12bwvnCcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Treinando nossos modelos com os melhores parâmetros**\n",
        "\n",
        "Agora que já sabemos o melhor valor de suavização (NaiveBayes), de learning rate (Regressão Logística), e da quantidade de vizinhos (KNN), vamos treinar nossos modelos com todo o conjunto de treinamento (X_train) e testá-lo no conjunto de teste que estava separado (X_test)."
      ],
      "metadata": {
        "id": "jIATa-H0Oygw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1c-_xIMz6hTc"
      },
      "outputs": [],
      "source": [
        "# Você deve instanciar e treinar os três modelos.\n",
        "# Dica: Use as classes que você usou SGDClassifier(), MultinomialNB() e KNeighborsClassifier(), passando o parâmetro selecionado conforme a validação cruzada\n",
        "# Lembre-se que vamos usar os dados vetorizados sem padronização para o Naive Bayes e os com padronização para os demais\n",
        "# Salve o modelo naive bayes na variável cnb, a regressão linear na variável clr e o KNN na variável knn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dQkxo_h9rEP"
      },
      "source": [
        "## **Avaliação dos modelos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SA8_uQbO9x4H"
      },
      "source": [
        "1. **Predições para cada modelo**\n",
        "\n",
        "Você deve realizar as predições para cada um dos três modelos. Para cada variável que guarda os objetos dos modelos gerados, use a predict(X_test). Lembre-se que o modelo naive bayes deve usar os dados da vetorização bag-of-words e os demais modelos os dados da vetorização bag-of-words que foram padronizados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfkEljQ1RUb2"
      },
      "outputs": [],
      "source": [
        "# Predição do Modelo: Naive Bayes\n",
        "\n",
        "print(cnb_pred[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d680M3r59wpx"
      },
      "outputs": [],
      "source": [
        "# Predição do Modelo: Regressão Logística\n",
        "\n",
        "print(clr_pred[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6lImQ0MRUU6"
      },
      "outputs": [],
      "source": [
        "# Predição do Modelo: KNN\n",
        "\n",
        "print(knn_pred[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p66jwQB_Zbk"
      },
      "source": [
        "2. **Plote a matriz de confusão para cada modelo.**\n",
        "\n",
        "Vamos investigar a relação de erros e acertos de cada modelo observando a matriz de confusão. Use as variáveis do passo anterior que armazenam as predições geradas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgk2WrgE_dFg"
      },
      "outputs": [],
      "source": [
        "# Faça o plot da matriz de confusão de contagem para cada um dos modelos.\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, labels=None) -> None:\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "\n",
        "    plt.figure(figsize=(len(labels), len(labels)))\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=True,\n",
        "        fmt='d',\n",
        "        cmap='Blues',\n",
        "        xticklabels=labels,\n",
        "        yticklabels=labels,\n",
        "    )\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5k6mTD5xSsCP"
      },
      "outputs": [],
      "source": [
        "# Modelo: Naive Bayes. Dica use: plot_confusion_matrix()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqZEN_1fSsPd"
      },
      "outputs": [],
      "source": [
        "# Modelo: Regressão Logística. Dica use: plot_confusion_matrix()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcMz9o9bS1Zo"
      },
      "outputs": [],
      "source": [
        "# Modelo: KNN. Dica use: plot_confusion_matrix()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Perguntas**\n",
        "\n",
        "Responda demonstrando o cálculo quando aplicável"
      ],
      "metadata": {
        "id": "--3N23WEoAw5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Qual modelo está sofrendo mais por conta de falsos positivos?\n",
        "- Resposta:"
      ],
      "metadata": {
        "id": "bX0tkvyKoC1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Qual modelo está sofrendo mais por conta de falsos negativos?\n",
        "- Resposta:"
      ],
      "metadata": {
        "id": "wNyGAQ0MqM7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Considerando a classe positiva, qual o modelo mais preciso?\n",
        "- Resposta:"
      ],
      "metadata": {
        "id": "6hIG-oHKqVPR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Considerando a classe positiva, qual o modelo tem melhor revocação?\n",
        "- Resposta:\n"
      ],
      "metadata": {
        "id": "wH5_OTCzqtQr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rssiJLR-h--"
      },
      "source": [
        "3. **Cálculo de Métricas.**\n",
        "\n",
        "Vamos calcular e imprimir todas as métricas (acurácia, recall, precision, f1-score). Para isso basta usar a função classification_report() da sklearn."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resultado para o modelo Naive Bayes\n",
        "print(classification_report(y_test, cnb_pred))"
      ],
      "metadata": {
        "id": "aKL95qpOuTa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resultado para o modelo de Regressão Logística\n",
        "print(classification_report(y_test, clr_pred))"
      ],
      "metadata": {
        "id": "aqFEps4Nuo5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resultado para o modelo KNN\n",
        "print(classification_report(y_test, knn_pred))"
      ],
      "metadata": {
        "id": "cRV6NbxFu10X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkC5heouJkyB"
      },
      "source": [
        "### **Perguntas**\n",
        "\n",
        "Responda Justificando"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. No nosso cenário, é adequado utilizar a métrica de acurácia?\n",
        "- Resposta:"
      ],
      "metadata": {
        "id": "_hV_9ga7x5o3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Considerando a classe negativa, qual é o modelo mais preciso?\n",
        "- Resposta:"
      ],
      "metadata": {
        "id": "0wYa4l_HyB5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Considerando a classe negativa, qual o modelo tem melhor revocação?\n",
        "- Resposta:"
      ],
      "metadata": {
        "id": "aoYlZugDyI1j"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LngzKUBy_vZy"
      },
      "source": [
        "## **Interpretando os modelos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38nrMM3s_yFI"
      },
      "source": [
        "**Uma subárea importante da aprendizagem de máquina é a interpretação dos modelos.**\n",
        "\n",
        "**Nesta parte do laboratório, você deve utilizará funções já implementadas para facilitar a interpretação dos modelos treinados e responder algumas perguntas sobre eles.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_ehN7jHBCRL"
      },
      "source": [
        "As funções a seguir utilizam informações das frequências e valores dos pesos dos modelos para encontrar as palavras que mais contribuem para classificação.\n",
        "\n",
        "O modelo de Regressão Logística tem um parâmetro chamado ***coef_*** este parâmetro retorna o peso de cada feature (palavra) tem no modelo. Palavras com peso positivo influenciam para a classificação positiva, e palavras com peso negativo fazem o inverso. O valor desse parâmetro tem a dimensão (1, n_features).\n",
        "\n",
        "Já o modelo Naive Bayes tem um parâmetro chamado ***feature_log_prob_***. Este parâmetro retorna o log das probabilidades de cada palavra aparecer no texto dada uma classe. O valor desse parâmetro tem a dimensão (2, n_features), de modo que a posição 0 corresponde as probabilidades para a classe negativa e a posição para a classe positiva. Quanto maior for a probabilidade de uma palavra, maior podemos dizer que é sua influência na classificação.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoEdrBABA3Mx"
      },
      "outputs": [],
      "source": [
        "def recupera_palavras_positivas(modelo, vectorizer, X_train=None, y_train=None):\n",
        "    # Verifica o tipo do modelo e obtém os coeficientes\n",
        "    if isinstance(modelo, SGDClassifier):\n",
        "        # Implemente aqui usando coef_[0]\n",
        "    elif isinstance(modelo, MultinomialNB):\n",
        "        # Implemente aqui usando feature_log_prob_[1]\n",
        "    elif isinstance(modelo, KNeighborsClassifier):\n",
        "        # Para KNN, vamos calcular a importância baseada na frequência das palavras nas instâncias positivas do conjunto de treino\n",
        "        indices_positivos = np.where(y_train == 'pos')[0]\n",
        "\n",
        "        # Verificar se existem instâncias positivas\n",
        "        if len(indices_positivos) == 0:\n",
        "            return \"Não há instâncias positivas no conjunto de treino\"\n",
        "\n",
        "        X_positivos = X_train[indices_positivos]\n",
        "\n",
        "        # Calcula a média das features para instâncias positivas\n",
        "        coeficientes = np.mean(X_positivos, axis=0)\n",
        "\n",
        "        # Se for uma matriz esparsa, converte para array\n",
        "        if hasattr(coeficientes, 'A1'):\n",
        "            coeficientes = coeficientes.A1\n",
        "    else:\n",
        "        coeficientes = modelo.coef_[0]\n",
        "\n",
        "    # Obter as palavras do vocabulário\n",
        "    palavras = vectorizer.get_feature_names_out()\n",
        "\n",
        "    # Ordenar as palavras pelos coeficientes de forma decrescente\n",
        "    palavras_positivas = np.argsort(coeficientes)[-20:][::-1]\n",
        "\n",
        "    return [(palavras[i], coeficientes[i]) for i in palavras_positivas]\n",
        "\n",
        "print(\"Regressão Logística: \" + str(recupera_palavras_positivas(clr, vectorizer)))\n",
        "print(\"Naive Bayes: \" + str(recupera_palavras_positivas(cnb, vectorizer)))\n",
        "print(\"KNN: \" + str(recupera_palavras_positivas(knn, vectorizer, X_train, y_train)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyXUmsDawbrh"
      },
      "outputs": [],
      "source": [
        "def recupera_palavras_negativas(modelo, vetorizer, X_train=None, y_train=None):\n",
        "    # Verifica o tipo do modelo e obtém os coeficientes\n",
        "    if isinstance(modelo, SGDClassifier):\n",
        "        # Implemente aqui usando coef_[0]\n",
        "    elif isinstance(modelo, MultinomialNB):\n",
        "        # Implemente aqui usando feature_log_prob_[1]\n",
        "    elif isinstance(modelo, KNeighborsClassifier):\n",
        "        # Para KNN, vamos calcular a importância baseada na frequência das palavras nas instâncias negativas do conjunto de treino\n",
        "        indices_negativos = np.where(y_train == 'neg')[0]\n",
        "\n",
        "        # Verificar se existem instâncias negativas\n",
        "        if len(indices_negativos) == 0:\n",
        "            return \"Não há instâncias negativas no conjunto de treino\"\n",
        "\n",
        "        X_negativos = X_train[indices_negativos]\n",
        "\n",
        "        # Calcula a média das features para instâncias negativas\n",
        "        coeficientes = np.mean(X_negativos, axis=0)\n",
        "\n",
        "        # Se for uma matriz esparsa, converte para array\n",
        "        if hasattr(coeficientes, 'A1'):\n",
        "            coeficientes = coeficientes.A1\n",
        "\n",
        "        # Filtrar valores NaN e infinitos logo após calcular\n",
        "        coeficientes = np.nan_to_num(coeficientes, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    else:\n",
        "        coeficientes = modelo.coef_[0]\n",
        "\n",
        "    # Obter as palavras do vocabulário\n",
        "    palavras = vetorizer.get_feature_names_out()\n",
        "\n",
        "    # Para outros modelos, também aplicar filtro NaN\n",
        "    if not isinstance(modelo, KNeighborsClassifier):\n",
        "        coeficientes = np.nan_to_num(coeficientes, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "    # Para KNN, filtrar palavras com coeficiente zero\n",
        "    if isinstance(modelo, KNeighborsClassifier):\n",
        "        # Pegar apenas índices onde coeficiente > 0\n",
        "        indices_nao_zero = np.where(coeficientes > 0)[0]\n",
        "        if len(indices_nao_zero) == 0:\n",
        "            return \"Não há palavras com coeficientes positivos\"\n",
        "\n",
        "        # Ordenar apenas os coeficientes não-zero de forma crescente\n",
        "        indices_ordenados = indices_nao_zero[np.argsort(-coeficientes[indices_nao_zero])[:20]]\n",
        "        return [(palavras[i], coeficientes[i]) for i in indices_ordenados]\n",
        "    else:\n",
        "        # Para outros modelos, manter como estava\n",
        "        palavras_negativas = np.argsort(coeficientes)[:20]\n",
        "        return [(palavras[i], coeficientes[i]) for i in palavras_negativas]\n",
        "\n",
        "print(\"Regressão Logística: \" + str(recupera_palavras_negativas(clr, vectorizer)))\n",
        "print(\"Naive Bayes: \" + str(recupera_palavras_negativas(cnb, vectorizer)))\n",
        "print(\"KNN: \" + str(recupera_palavras_negativas(knn, vectorizer, X_train, y_train)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPowzyW5IhxU"
      },
      "source": [
        "### **Visualizando e interpretando**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx2ysoeWG2Os"
      },
      "source": [
        "Use a função abaixo para visualizar uma nuvem de palavras do retorno das funções."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mh8jeA9PEvQP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "def plot_wordcloud(lista_de_tuplas):\n",
        "    # Cria um dicionário a partir da lista de tuplas\n",
        "    palavra_freq = {t[0]: t[1] for t in lista_de_tuplas}\n",
        "\n",
        "    # Cria a WordCloud\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(palavra_freq)\n",
        "\n",
        "    # Plota a WordCloud\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfeIOuLWIuqT"
      },
      "source": [
        "#### **Palavras positivas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PET-3-1hIA3C"
      },
      "outputs": [],
      "source": [
        "# Regressão Logística\n",
        "Y = recupera_palavras_positivas(clr, vectorizer)\n",
        "plot_wordcloud(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NwE8KQ_IFIg"
      },
      "outputs": [],
      "source": [
        "# Naive Bayes\n",
        "Y = recupera_palavras_positivas(cnb, vectorizer)\n",
        "plot_wordcloud(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VO2RJNviIKGN"
      },
      "outputs": [],
      "source": [
        "# KNN\n",
        "Y = recupera_palavras_positivas(knn, vectorizer, X_train, y_train)\n",
        "plot_wordcloud(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLAyhmb6IyVW"
      },
      "source": [
        "#### **Palavras negativas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4k-H_fmoI3DQ"
      },
      "outputs": [],
      "source": [
        "# Regressão Logística\n",
        "Y = recupera_palavras_negativas(clr, vectorizer)\n",
        "plot_wordcloud(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suI-KPZFI3DS"
      },
      "outputs": [],
      "source": [
        "# Naive Bayes\n",
        "Y = recupera_palavras_negativas(cnb, vectorizer)\n",
        "plot_wordcloud(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKzprfNuI3DS"
      },
      "outputs": [],
      "source": [
        "# KNN\n",
        "Y = recupera_palavras_negativas(knn, vectorizer, X_train, y_train)\n",
        "plot_wordcloud(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrzXYtiMHFYB"
      },
      "source": [
        "#### **Perguntas**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwI3igQAHHUf"
      },
      "source": [
        "**1. Analisando as nuvens de palavras positivas de cada modelo, é possível identificar que as palavras estão associadas à um sentimento positivo? Dê exemplos.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qikrH9SSHc8W"
      },
      "source": [
        "- Resposta:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unzddM3NHf2t"
      },
      "source": [
        "**2. Analisando as nuvens de palavras negativas de cada modelo, é possível identificar que as palavras estão associadas à um sentimento negativo? Dê exemplos.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlvPk8gxHlCi"
      },
      "source": [
        "- Resposta:\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KbKHnZiNj2Uk",
        "LjPuNmPvkFrq",
        "K4Qyfdx0k64m",
        "r3FWA1Fz3kIB",
        "UrOIsxtZ4BWd",
        "cfKF_CEwhQEl",
        "7dQkxo_h9rEP",
        "--3N23WEoAw5",
        "LkC5heouJkyB",
        "LngzKUBy_vZy",
        "pPowzyW5IhxU",
        "UfeIOuLWIuqT",
        "hLAyhmb6IyVW",
        "FrzXYtiMHFYB"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}